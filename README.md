<div align="center">
  <svg width="140" height="33" viewBox="0 0 140 33" fill="none" xmlns="http://www.w3.org/2000/svg">
<g clip-path="url(#clip0_590_13650)">
<path d="M18.0972 3.67218C18.0972 2.91949 17.4866 2.3087 16.7371 2.3087C15.9877 2.3087 15.3771 2.92088 15.3771 3.67218V26.2711C15.3771 28.02 13.9574 29.4433 12.2129 29.4433C10.4684 29.4433 9.04861 28.02 9.04861 26.2711V11.7724C9.04861 11.0197 8.43796 10.4089 7.68853 10.4089C6.93911 10.4089 6.32846 11.021 6.32846 11.7724V17.9177C6.32846 19.6666 4.90871 21.0899 3.16421 21.0899C1.41972 21.0899 0 19.6666 0 17.9177V15.6903C0 15.1908 0.403857 14.7859 0.902086 14.7859C1.40032 14.7859 1.80417 15.1908 1.80417 15.6903V17.9177C1.80417 18.6704 2.41479 19.2812 3.16421 19.2812C3.91364 19.2812 4.52429 18.669 4.52429 17.9177V11.7724C4.52429 10.0235 5.94404 8.60017 7.68853 8.60017C9.43303 8.60017 10.8528 10.0235 10.8528 11.7724V26.2711C10.8528 27.0238 11.4634 27.6346 12.2129 27.6346C12.9623 27.6346 13.5729 27.0224 13.5729 26.2711V17.4057V3.67218C13.5729 1.92331 14.9926 0.5 16.7371 0.5C18.4816 0.5 19.9014 1.92331 19.9014 3.67218V22.3852C19.9014 22.8847 19.4975 23.2896 18.9993 23.2896C18.5011 23.2896 18.0972 22.8847 18.0972 22.3852V3.67218ZM34.8358 8.60017C33.0913 8.60017 31.6715 10.0235 31.6715 11.7724V23.8836C31.6715 24.6363 31.0609 25.2471 30.3115 25.2471C29.562 25.2471 28.9514 24.635 28.9514 23.8836V3.67218C28.9514 1.92331 27.5316 0.5 25.7871 0.5C24.0426 0.5 22.6229 1.92331 22.6229 3.67218V29.3278C22.6229 30.0805 22.0123 30.6913 21.2629 30.6913C20.5134 30.6913 19.9028 30.0791 19.9028 29.3278V26.1515C19.9028 25.652 19.4989 25.2471 19.0007 25.2471C18.5025 25.2471 18.0986 25.652 18.0986 26.1515V29.3278C18.0986 31.0767 19.5184 32.5 21.2629 32.5C23.0074 32.5 24.4271 31.0767 24.4271 29.3278V3.67218C24.4271 2.91949 25.0377 2.3087 25.7871 2.3087C26.5366 2.3087 27.1472 2.92088 27.1472 3.67218V23.8836C27.1472 25.6325 28.567 27.0558 30.3115 27.0558C32.056 27.0558 33.4757 25.6325 33.4757 23.8836V11.7724C33.4757 11.0197 34.0864 10.4089 34.8358 10.4089C35.5852 10.4089 36.1958 11.021 36.1958 11.7724V22.3852C36.1958 22.8847 36.5997 23.2896 37.0979 23.2896C37.5961 23.2896 38 22.8847 38 22.3852V11.7724C38 10.0235 36.5803 8.60017 34.8358 8.60017Z" fill="url(#paint0_linear_590_13650)"/>
<path d="M60.9293 8.5H63.4336C63.5054 8.5 63.5649 8.5244 63.6157 8.57493C63.6647 8.62545 63.691 8.68467 63.691 8.7561V23.147C63.691 23.2184 63.6665 23.2776 63.6157 23.3282C63.5649 23.3787 63.5054 23.4031 63.4336 23.4031H60.9293C60.8575 23.4031 60.798 23.3787 60.7472 23.3282C60.6964 23.2794 60.6719 23.2184 60.6719 23.147V13.7598C60.6719 13.7041 60.6579 13.6745 60.6299 13.6745C60.6019 13.6745 60.5721 13.6954 60.5441 13.7389L58.2763 17.2722C58.2045 17.3854 58.1046 17.4429 57.9768 17.4429H56.7142C56.5863 17.4429 56.4865 17.3871 56.4147 17.2722L54.1469 13.7389C54.1189 13.6971 54.0891 13.6779 54.0611 13.6849C54.0331 13.6919 54.0191 13.725 54.0191 13.7807V23.147C54.0191 23.2184 53.9946 23.2776 53.9438 23.3282C53.893 23.3787 53.8335 23.4031 53.7617 23.4031H51.2574C51.1856 23.4031 51.1261 23.3787 51.0753 23.3282C51.0245 23.2794 51 23.2184 51 23.147V8.7561C51 8.68467 51.0245 8.62545 51.0753 8.57493C51.1261 8.5244 51.1856 8.5 51.2574 8.5H53.7617C53.8895 8.5 53.9893 8.55749 54.0611 8.67074L57.2711 13.6309C57.3131 13.7163 57.3569 13.7163 57.3989 13.6309L60.6299 8.67074C60.7017 8.55749 60.8015 8.5 60.9293 8.5Z" fill="currentColor"/>
<path d="M66.3725 23.3282C66.3217 23.2794 66.2971 23.2184 66.2971 23.147V8.7561C66.2971 8.68467 66.3217 8.62545 66.3725 8.57493C66.4232 8.5244 66.4827 8.5 66.5545 8.5H69.0588C69.1306 8.5 69.1901 8.5244 69.2409 8.57493C69.2899 8.62545 69.3162 8.68467 69.3162 8.7561V23.147C69.3162 23.2184 69.2917 23.2776 69.2409 23.3282C69.1901 23.3787 69.1306 23.4031 69.0588 23.4031H66.5545C66.4827 23.4031 66.4232 23.3787 66.3725 23.3282Z" fill="#181E25"/>
<path d="M79.7649 8.57667C79.814 8.52789 79.8752 8.50174 79.947 8.50174H82.4512C82.523 8.50174 82.5826 8.52614 82.6334 8.57667C82.6824 8.62719 82.7087 8.68642 82.7087 8.75785V23.1487C82.7087 23.2202 82.6842 23.2794 82.6334 23.3299C82.5826 23.3804 82.523 23.4048 82.4512 23.4048H80.0328C79.8892 23.4048 79.7894 23.3491 79.7334 23.2341L74.1908 14.1222C74.1628 14.0804 74.133 14.0612 74.105 14.0682C74.077 14.0752 74.063 14.1083 74.063 14.164L74.105 23.147C74.105 23.2184 74.0805 23.2776 74.0297 23.3282C73.9789 23.3787 73.9194 23.4031 73.8476 23.4031H71.3434C71.2716 23.4031 71.212 23.3787 71.1612 23.3282C71.1104 23.2794 71.0859 23.2184 71.0859 23.147V8.7561C71.0859 8.68467 71.1104 8.62545 71.1612 8.57493C71.212 8.5244 71.2716 8.5 71.3434 8.5H73.7618C73.9036 8.5 74.0034 8.55749 74.0612 8.67074L79.581 17.7391C79.6091 17.7809 79.6371 17.8001 79.6668 17.7931C79.6949 17.7861 79.7089 17.7548 79.7089 17.6973L79.6878 8.7561C79.6878 8.68467 79.7124 8.62545 79.7632 8.57493L79.7649 8.57667Z" fill="#181E25"/>
<path d="M86.2237 23.3282C86.1729 23.2794 86.1484 23.2184 86.1484 23.147V8.7561C86.1484 8.68467 86.1729 8.62545 86.2237 8.57493C86.2745 8.5244 86.3341 8.5 86.4059 8.5H88.9101C88.9819 8.5 89.0414 8.5244 89.0922 8.57493C89.1413 8.62545 89.1675 8.68467 89.1675 8.7561V23.147C89.1675 23.2184 89.143 23.2776 89.0922 23.3282C89.0414 23.3787 88.9819 23.4031 88.9101 23.4031H86.4059C86.3341 23.4031 86.2745 23.3787 86.2237 23.3282Z" fill="#181E25"/>
<path d="M101.711 8.5H104.215C104.287 8.5 104.346 8.5244 104.397 8.57493C104.446 8.62545 104.472 8.68467 104.472 8.7561V23.147C104.472 23.2184 104.448 23.2776 104.397 23.3282C104.346 23.3787 104.287 23.4031 104.215 23.4031H101.711C101.639 23.4031 101.579 23.3787 101.528 23.3282C101.478 23.2794 101.453 23.2184 101.453 23.147V13.7598C101.453 13.7041 101.439 13.6745 101.411 13.6745C101.383 13.6745 101.353 13.6954 101.325 13.7389L99.0575 17.2722C98.9857 17.3854 98.8859 17.4429 98.7581 17.4429H97.4955C97.3676 17.4429 97.2678 17.3871 97.196 17.2722L94.9282 13.7389C94.9001 13.6971 94.8704 13.6779 94.8424 13.6849C94.8143 13.6919 94.8003 13.725 94.8003 13.7807V23.147C94.8003 23.2184 94.7758 23.2776 94.725 23.3282C94.6743 23.3787 94.6147 23.4031 94.5429 23.4031H92.0387C91.9669 23.4031 91.9073 23.3787 91.8565 23.3282C91.8058 23.2794 91.7812 23.2184 91.7812 23.147V8.7561C91.7812 8.68467 91.8058 8.62545 91.8565 8.57493C91.9073 8.5244 91.9669 8.5 92.0387 8.5H94.5429C94.6707 8.5 94.7706 8.55749 94.8424 8.67074L98.0523 13.6309C98.0944 13.7163 98.1381 13.7163 98.1802 13.6309L101.411 8.67074C101.483 8.55749 101.583 8.5 101.711 8.5Z" fill="currentColor"/>
<path d="M116.327 23.1888L115.685 21.1033C115.657 21.0476 115.62 21.018 115.578 21.018H110.314C110.272 21.018 110.235 21.0458 110.207 21.1033L109.587 23.1888C109.545 23.3317 109.452 23.4013 109.308 23.4013H106.591C106.505 23.4013 106.44 23.3769 106.398 23.3264C106.356 23.2776 106.347 23.2027 106.377 23.1034L110.998 8.71255C111.04 8.57143 111.133 8.5 111.277 8.5H114.636C114.777 8.5 114.87 8.57143 114.914 8.71255L119.535 23.1034C119.55 23.1313 119.557 23.1679 119.557 23.2097C119.557 23.3369 119.478 23.4013 119.322 23.4013H116.604C116.462 23.4013 116.369 23.3299 116.326 23.1888H116.327ZM111.063 18.6973H114.83C114.916 18.6973 114.944 18.6555 114.916 18.5701L112.99 12.2476C112.975 12.1918 112.954 12.1657 112.925 12.1726C112.897 12.1796 112.874 12.204 112.86 12.2476L110.977 18.5701C110.963 18.6555 110.991 18.6973 111.063 18.6973Z" fill="currentColor"/>
<path d="M120.8 23.3179C120.758 23.2622 120.765 23.1908 120.821 23.1054L124.972 16.0162C125 15.9744 125 15.9309 124.972 15.889L120.821 8.79987L120.779 8.67269C120.779 8.55944 120.858 8.50195 121.014 8.50195H123.732C123.874 8.50195 123.981 8.55944 124.052 8.67269L126.833 13.5475C126.875 13.6328 126.919 13.6328 126.961 13.5475L129.742 8.67269C129.814 8.55944 129.921 8.50195 130.063 8.50195H132.759C132.859 8.50195 132.931 8.52983 132.973 8.58732C133.015 8.64481 133.008 8.7145 132.952 8.79987L128.802 15.889C128.788 15.9309 128.788 15.9744 128.802 16.0162L132.952 23.1054L132.994 23.2326C132.994 23.3458 132.915 23.4033 132.759 23.4033H130.063C129.919 23.4033 129.812 23.3476 129.742 23.2326L126.961 18.3787C126.919 18.2933 126.875 18.2933 126.833 18.3787L124.03 23.2326C123.958 23.3458 123.851 23.4033 123.709 23.4033H121.012C120.913 23.4033 120.841 23.3754 120.799 23.3179H120.8Z" fill="currentColor"/>
</g>
<defs>
<linearGradient id="paint0_linear_590_13650" x1="-0.00138782" y1="16.5" x2="38.0014" y2="16.5" gradientUnits="userSpaceOnUse">
<stop stop-color="#E21680"/>
<stop offset="1" stop-color="#FF633A"/>
</linearGradient>
<clipPath id="clip0_590_13650">
<rect width="140" height="32" fill="white" transform="translate(0 0.5)"/>
</clipPath>
</defs>
</svg>

</div>
<hr>

<div align="center" style="line-height: 1;">
  <a href="https://www.minimaxi.com/en" target="_blank" style="margin: 2px;">
    <img alt="Homepage" src="https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-square&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWidth=20" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://huggingface.co/MiniMaxAI" target="_blank" style="margin: 2px;">
    <img alt="Hugging Face" src="https://img.shields.io/badge/🤗_Hugging_Face-MinMax-FF4040?style=flat-square&labelColor=2C3E50" style="display: inline-block; vertical-align: middle;"/>
  </a>
</div>
<div align="center" style="line-height: 1;">
  <a href="https://www.hailuo.ai/" target="_blank" style="margin: 2px;">
    <img alt="Chat" src="https://img.shields.io/badge/Chat-_Hailuo AI-FF4040?style=flat-square&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgMzc1LjE0IDM3NS4xNCI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOnVybCgjdW5uYW1lZC1ncmFkaWVudCk7fTwvc3R5bGU+PGxpbmVhckdyYWRpZW50IGlkPSJ1bm5hbWVkLWdyYWRpZW50IiB4MT0iOC40MiIgeTE9IjEzLjgxIiB4Mj0iNDI5LjY1IiB5Mj0iNDIyLjM3IiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSI+PHN0b3Agb2Zmc2V0PSIwLjA5IiBzdG9wLWNvbG9yPSIjZmZhYjBjIi8+PHN0b3Agb2Zmc2V0PSIwLjMxIiBzdG9wLWNvbG9yPSIjZmY1NTM4Ii8+PHN0b3Agb2Zmc2V0PSIwLjQ2IiBzdG9wLWNvbG9yPSIjZTk0MDVkIi8+PHN0b3Agb2Zmc2V0PSIwLjc1IiBzdG9wLWNvbG9yPSIjZDI2NmRhIi8+PHN0b3Agb2Zmc2V0PSIwLjg5IiBzdG9wLWNvbG9yPSIjZDU4NGVmIi8+PC9saW5lYXJHcmFkaWVudD48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMzc1LjE0LDE4Ny41N0MzNzUuMTQsODQsMjkwLjc0LS4yNiwxODcuMDksMCw4NC4yNi4yNi4yNiw4NC4yNSwwLDE4Ny4wOWMtLjI2LDEwMy42NSw4NCwxODgsMTg3LjU3LDE4OEgzMTAuODJBNjQuMjEsNjQuMjEsMCwwLDAsMzc1LDMxMC45M1YxOTMuODJoMEMzNzUuMDksMTkxLjc5LDM3NS4xNCwxODkuNjcsMzc1LjE0LDE4Ny41N1ptLTI4NCwxMDQuMTdjLTI5Ljg2LTI1LjQ5LTQ4LjI2LTY2LjI3LTQ3LjQtMTA3Ljg1cS4wOS00LjM4LjQ2LTguNzNWMTc1YzQuMzItNDkuNiwzNi4zNy05NS44OCw4MS4yOS0xMTcuMzZTMjI2LjUyLDQwLjIxLDI2Ny44NSw2OHM2Ni4zMiw3OC4yMSw2My40LDEyNy45MmExNzgsMTc4LDAsMCwxLTUuMTQsMzIuMjVjLTEsNC4yLTIuMyw4LjU3LTUuMjgsMTEuNzJzLTguMiw0LjYtMTEuNzMsMi4wOWMtMy4zNy0yLjQxLTMuODctNy4xMi00LjE2LTExLjI1LTIuMzMtMzMuMzctMTEuMjQtNjcuNzYtMzMuNzktOTIuNDdhMTAzLjY3LDEwMy42NywwLDAsMC02Ni4zOC0zMi44NEExMDcuMTksMTA3LjE5LDAsMCwwLDEzMy4yMiwxMjVDMTE2LDEzNy4yNywxMDIuNTUsMTU0Ljg4LDk2LDE3NXMtNS44Niw0Mi42MSwyLjcxLDYxLjkzYTgxLjg5LDgxLjg5LDAsMCwwLDI5LjcxLDM1YzIyLjk0LDE1LjA2LDU0LjMxLDE3LjIsNzguMTQsMy42czM4LjA3LTQzLjEsMzItNjkuODZTMjA1LjQsMTU4LDE3OC4xMSwxNjAuODRjLTQuMTYuNDMtMTAuMTMsMC0xMC4yOC00LjIxLS4xMi0zLjI0LDMuNzctNC45NCw3LTUuNTIsMjcuNjgtNSw1Ny4zNCw5LjA5LDcyLjUzLDMyLjc3czE2LDU1LjQxLDMuNTYsODAuNjYtMzcsNDMuNjktNjQuMzYsNTAuMzVDMTQ5LjY4LDMyMy44NywxMTYuMzEsMzEzLjI1LDkxLjExLDI5MS43NFoiLz48L3N2Zz4=&logoWidth=16" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://intl.minimaxi.com" style="margin: 2px;">
    <img alt="API" src="https://img.shields.io/badge/⚡_API-Platform-FF4040?style=flat-square&labelColor=2C3E50" style="display: inline-block; vertical-align: middle;"/>
  </a>
</div>
<div align="center" style="line-height: 1;">
  <a href="https://github.com/MiniMax-AI/MiniMax-01/blob/main/LICENSE" style="margin: 2px;">
    <img alt="License" src="https://img.shields.io/badge/📜_License-Model_Agreement-FF4040?style=flat-square&labelColor=2C3E50" style="display: inline-block; vertical-align: middle;"/>
  </a>
</div>


# MiniMax-Text-01

## 1. Introduction

MiniMax-Text-01 is a powerful language model with 456 billion total parameters, of which 45.9 billion are activated per token. To better unlock the long context capabilities of the model, MiniMax-Text-01 adopts a hybrid architecture that combines Lightning Attention, Softmax Attention and Mixture-of-Experts (MoE). Leveraging advanced parallel strategies and innovative compute-communication overlap methods—such as Linear Attention Sequence Parallelism Plus (LASP+), varlen ring attention, Expert Tensor Parallel (ETP), etc., MiniMax-Text-01's training context length is extended to 1 million tokens, and it can handle a context of up to 4 million tokens during the inference. On various academic benchmarks, MiniMax-Text-01 also demonstrates the performance of a top-tier model.

<p align="center">
  <img width="100%" src="figures/TextBench.png">
</p>

## 2. Model Architecture

The architecture of MiniMax-Text-01 is briefly described as follows:
- Total Parameters: 456B
- Activated Parameters per Token: 45.9B
- Number Layers: 80
- Hybrid Attention: a softmax attention is positioned after every 7 lightning attention.
  - Number of attention heads: 64
  - Attention head dimension: 128
- Mixture of Experts:
  - Number of experts: 32
  - Expert hidden dimension: 9216
  - Top-2 routing strategy
- Positional Encoding: Rotary Position Embedding (RoPE) applied to half of the attention head dimension with a base frequency of 10,000,000
- Hidden Size: 6144
- Vocab Size: 200,064

## 3. Evaluation

### Core Academic Benchmarks

| **Tasks**                     | **GPT-4o (11-20)** | **Claude-3.5-Sonnet (10-22)** | **Gemini-1.5-Pro (002)** | **Gemini-2.0-Flash (exp)** | **Qwen2.5-72B-Inst.** | **DeepSeek-V3** | **Llama-3.1-405B-Inst.** | **MiniMax-Text-01** |
|-------------------------------|--------------------|-------------------------------|--------------------------|----------------------------|-----------------------|-----------------|--------------------------|---------------------|
| **General**                   |                    |                               |                          |                            |                       |                 |                          |                     |
| MMLU<sup>*</sup>                      | 85.7               | 88.3                          | 86.8                     | 86.5                       | 86.1                  | 88.5        | **88.6**                 | 88.5                |
| MMLU-Pro<sup>*</sup>                  | 74.4               | **78.0**                      | 75.8                     | 76.4                       | 71.1                  | 75.9            | 73.3                     | 75.7                |
| SimpleQA                      | **39.0**           | 28.1                          | 23.4                     | 26.6                       | 10.3                  | 24.9            | 23.2                     | 23.7                |
| C-SimpleQA                    | 64.6               | 56.8                          | 59.4                     | 63.3                       | 52.2                  | 64.8            | 54.7                     | **67.4**            |
| IFEval _(avg)_                | 84.1               | **90.1**                      | 89.4                     | 88.4                       | 87.2                  | 87.3            | 86.4                     | 89.1                |
| Arena-Hard                    | **92.4**           | 87.6                          | 85.3                     | 72.7                       | 81.2                  | 91.4            | 63.5                     | 89.1                |
| **Reasoning**                 |                    |                               |                          |                            |                       |                 |                          |                     |
| GPQA<sup>*</sup> _(diamond)_          | 46.0               | **65.0**                      | 59.1                     | 62.1                       | 49.0                  | 59.1            | 50.7                     | 54.4                |
| DROP<sup>*</sup> _(F1)_               | 89.2               | 88.8                          | 89.2                     | 89.3                       | 85.0                  | 91.0        | **92.5**                 | 87.8                |
| **Mathematics**               |                    |                               |                          |                            |                       |                 |                          |                     |
| GSM8k<sup>*</sup>                     | 95.6               | **96.9**                      | 95.2                     | 95.4                       | 95.8                  | 96.7            | 96.7                     | 94.8                |
| MATH<sup>*</sup>                      | 76.6               | 74.1                          | **84.6**                 | 83.9                       | 81.8                  | **84.6**        | 73.8                     | 77.4                |
| **Coding**                    |                    |                               |                          |                            |                       |                 |                          |                     |
| MBPP +                        | 76.2               | 75.1                          | 75.4                     | 75.9                       | 77.0              | **78.8**        | 73.0                     | 71.7                |
| HumanEval                     | 90.2               | **93.7**                      | 86.6                     | 89.6                       | 86.6                  | 92.1            | 89.0                     | 86.9                |

<sup>*</sup> Evaluated following a _0-shot CoT_ setting.

### Long Benchmarks
#### 4M Needle In A Haystack Test
<p align="center">
  <img width="90%" src="figures/niah.png">
</p>

#### Ruler
| Model | 4k | 8k | 16k | 32k | 64k | 128k | 256k | 512k | 1M |
|-------|----|----|-----|-----|-----|------|------|------|----|
| **GPT-4o (11-20)** | **0.970** | 0.921 | 0.890 | 0.888 | 0.884 | - | - | - | - |
| **Claude-3.5-Sonnet (10-22)** | 0.965 | 0.960 | 0.957 | 0.950 | **0.952** | 0.938 | - | - | - |
| **Gemini-1.5-Pro (002)** | 0.962 | 0.960 | **0.960** | **0.958** | 0.938 | 0.917 | 0.916 | 0.861 | 0.850 |
| **Gemini-2.0-Flash (exp)** | 0.960 | 0.960 | 0.951 | 0.957 | 0.937 | 0.860 | 0.797 | 0.709 | - |
| **MiniMax-Text-01** | 0.963 | **0.961** | 0.953 | 0.954 | 0.943 | **0.947** | **0.945** | **0.928** | **0.910** |

#### LongBench v2
| **Model**                  | **overall** | **easy** | **hard** | **short** | **medium** | **long** |
|----------------------------|-------------|----------|----------|------------|------------|----------|
| Human                      | 53.7        | 100.0    | 25.1     | 47.2       | 59.1       | 53.7     |
| **w/ CoT**                 |             |          |          |            |            |          |
| GPT-4o (11-20)             | 51.4        | 54.2     | 49.7     | 59.6       | 48.6       | 43.5     |
| Claude-3.5-Sonnet (10-22)  | 46.7        | 55.2     | 41.5     | 53.9       | 41.9       | 44.4     |
| Deepseek-V3                | -           | -        | -        | -          | -          | -        |
| Qwen2.5-72B-Inst.          | 43.5        | 47.9     | 40.8     | 48.9       | 40.9       | 39.8     |
| **MiniMax-Text-01**        | **56.5**    | **66.1** | **50.5** | **61.7**   | **56.7**   | **47.2** |
| **w/o CoT**                |             |          |          |            |            |          |
| GPT-4o (11-20)             | 50.1        | 57.4     | 45.6     | 53.3       | 52.4       | 40.2     |
| Claude-3.5-Sonnet (10-22)  | 41.0        | 46.9     | 37.3     | 46.1       | 38.6       | 37.0     |
| Deepseek-V3                | 48.7        | -        | -        | -          | -          | -        |
| Qwen2.5-72B-Inst.          | 42.1        | 42.7     | 41.8     | 45.6       | 38.1       | **44.4** |
| **MiniMax-Text-01**        | **52.9**    | **60.9** | **47.9** | **58.9**   | **52.6**   | 43.5     |

#### MTOB
| **Context Type** | **no context** | **half book** | **full book** | **Δ half book** | **Δ full book** |
|------------------|----------------|---------------|---------------|------------------|-----------------|
| **eng → kalam (ChrF)** | | | | | |
| GPT-4o (11-20) | 9.90 | **54.30** | - | 44.40 | - |
| Claude-3.5-Sonnet (10-22) | 20.22 | 53.62 | 55.65 | 33.39 | 35.42 |
| Gemini-1.5-Pro (002) | 16.79 | 53.68 | **57.90** | 36.89 | 41.11 |
| Gemini-2.0-Flash (exp) | 12.20 | 49.50 | 53.30 | 37.30 | 41.10 |
| Qwen-Long | 16.55 | 48.48 | 45.94 | 31.92 | 29.39 |
| **MiniMax-Text-01** | 6.0 | 51.74 | 51.60 | **45.7** | **45.6** |
| **kalam → eng (BLEURT)** | | | | | |
| GPT-4o (11-20) | 33.20 | 58.30 | - | 25.10 | - |
| Claude-3.5-Sonnet (10-22) | 31.42 | 59.70 | 62.30 | 28.28 | 30.88 |
| Gemini-1.5-Pro (002) | 32.02 | **61.52** | **63.09** | **29.50** | **31.07** |
| Gemini-2.0-Flash (exp) | 33.80 | 57.50 | 57.00 | 23.70 | 23.20 |
| Qwen-Long | 30.13 | 53.14 | 32.15 | 23.01 | 2.02 |
| **MiniMax-Text-01** | 33.65 | 57.10 | 58.00 | 23.45 | 24.35 |


## 4. Quickstart
Here we provide a simple example of loading the tokenizer and model to generate content.
```python
from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, QuantoConfig, GenerationConfig

# load hf config
hf_config = AutoConfig.from_pretrained("MiniMax-Text-01", trust_remote_code=True)

# quantization config, int8 is recommended
quantization_config =  QuantoConfig(
            weights="int8",
            modules_to_not_convert=[
                "lm_head",
                "embed_tokens",
            ] + [f"model.layers.{i}.coefficient" for i in range(hf_config.num_hidden_layers)]
            + [f"model.layers.{i}.block_sparse_moe.gate" for i in range(hf_config.num_hidden_layers)]
        )

# set device map
device_map = {
    'model.embed_tokens': 'cuda:0',
    'model.norm': f'cuda:{world_size - 1}',
    'lm_head': f'cuda:{world_size - 1}'
}
# assume 8 GPUs
world_size = 8
layers_per_device = hf_config.num_hidden_layers // world_size
for i in range(world_size):
    for j in range(layers_per_device):
        device_map[f'model.layers.{i * layers_per_device + j}'] = f'cuda:{i}'

# load tokenizer
tokenizer = AutoTokenizer.from_pretrained("MiniMax-Text-01")
prompt = "Hello!"
messages = [
    {"role": "system", "content": [{"type": "text", "text": "You are a helpful assistant created by MiniMax based on MiniMax-Text-01 model."}]},
    {"role": "user", "content": [{"type": "text", "text": prompt}]},
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
# tokenize and move to device
model_inputs = tokenizer(text, return_tensors="pt").to("cuda")

# load bfloat16 model, move to device, and apply quantization
quantized_model = AutoModelForCausalLM.from_pretrained(
    "MiniMax-Text-01",
    torch_dtype="bfloat16",
    device_map=device_map,
    quantization_config=quantization_config,
    trust_remote_code=True,
    offload_buffers=True,
)

# generate response
generation_config = GenerationConfig(
    max_new_tokens=20,
    eos_token_id=200020,
    use_cache=True,
)
generated_ids = quantized_model.generate(**model_inputs, generation_config=generation_config)
print(f"generated_ids: {generated_ids}")
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
```

## 5. Chatbot & API
For general use and evaluation, we provide a [Chatbot](https://www.hailuo.ai/) with online search capabilities and the [online API](https://intl.minimaxi.com) for developers.

Contact us at [model@minimaxi.com](mailto:model@minimaxi.com).
